{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g1 = tf.Graph()\n",
    "with g1.as_default():\n",
    "    a = tf.constant(5)\n",
    "    b = tf.constant(6)\n",
    "    c = tf.multiply(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph = g1) as sess1:\n",
    "    output1 = sess1.run(c)\n",
    "    replace_dict = {a:15}\n",
    "    output2 = sess1.run(c,feed_dict = replace_dict)\n",
    "    #print(output1,output2,a.eval())\n",
    "    \n",
    "    #Saving the graph in an object\n",
    "    #writer = tf.summary.FileWriter('./TF1')\n",
    "    #writer.add_graph(sess1.graph)\n",
    "    #writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g2 = tf.Graph()\n",
    "with g2.as_default():\n",
    "    a = tf.placeholder(tf.int32,shape=[2,None])\n",
    "    d = tf.add(a,a)\n",
    "    B = tf.zeros([3,3,3])\n",
    "    ones = tf.ones([3,3,3])\n",
    "    uni = tf.random_uniform([3,3,3], minval = 0, maxval = 10)\n",
    "    norm = tf.random_normal([3,3,3], mean = 5, stddev = 2)\n",
    "    ran = tf.add(B,tf.add(ones,tf.add(uni,norm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph = g2) as sess2:\n",
    "    input_dict = {a:np.array([[5,3],[2,1]],dtype = np.int32)}\n",
    "    output1 = sess2.run(d,feed_dict = input_dict)\n",
    "    output2 = sess2.run(ran)\n",
    "    #print(output1,d,'\\n\\n',output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Scope_A\"):\n",
    "    a = tf.Variable(0, name = 'a', trainable = True)\n",
    "    b = tf.Variable(1, name = 'b', trainable = True)\n",
    "with tf.name_scope(\"Scope_B\"):\n",
    "    c = tf.Variable(2, name = 'c', trainable = True)\n",
    "    d = tf.Variable(3, name = 'a', trainable = True)\n",
    "with tf.name_scope(\"Scope_C\"):\n",
    "    e = tf.add(a, c, name = 'output1')\n",
    "    f = tf.add(b, d, name = 'output2')\n",
    "\n",
    "g = tf.add(e,f)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "output = sess.run(g)\n",
    "#print(output)\n",
    "\n",
    "writer = tf.summary.FileWriter('./TF1')\n",
    "writer.add_graph(sess.graph)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(1)\n",
    "y = x + 1\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    #init.run() to initialize all the variables\n",
    "    x.initializer.run()\n",
    "    output1 = sess.run(y)\n",
    "    output2 = y.eval()\n",
    "    #print(output1,output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "with tf.Session() as sess:\n",
    "    y_val,z_val = sess.run([y,z])\n",
    "    #print(y_val)# 10\n",
    "    #print(z_val)# 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nsamples = 10000\n",
    "nvar = 2;\n",
    "nfact = 1;\n",
    "\n",
    "F = np.zeros(shape=(nsamples,nvar),dtype = np.float64);\n",
    "F[:,0] = np.random.random(nsamples);\n",
    "F[:,1] = 2*F[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.constant(F[:,0], shape = [nsamples,1], name = \"X\",dtype = tf.float64)\n",
    "y = tf.constant(F[:,1], shape = [nsamples,1], name = \"y\",dtype = tf.float64)\n",
    "#XT = tf.transpose(X)\n",
    "#theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "#with tf.Session() as sess:\n",
    "    #theta_value = sess.run(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.99648206]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "theta = tf.Variable(tf.cast(tf.Variable(tf.random_uniform([1, 1], -1.0, 1.0), name = \"theta\"), tf.float64))\n",
    "y_pred = tf.matmul(X, theta, name = \"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error),name = \"mse\")\n",
    "\n",
    "gradients = tf.gradients(mse, [theta])[0]\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            #print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "            pass\n",
    "        sess.run(training_op)     \n",
    "    best_theta = theta.eval()\n",
    "best_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.99651397]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimizers\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "theta = tf.Variable(tf.cast(tf.Variable(tf.random_uniform([1, 1], -1.0, 1.0), name = \"theta\"), tf.float64))\n",
    "y_pred = tf.matmul(X, theta, name = \"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error),name = \"mse\")\n",
    "\n",
    "#Momentum optimizer is faster \n",
    "optimizer1 = tf.train.MomentumOptimizer(learning_rate = learning_rate, momentum = 0.9)\n",
    "optimizer2 = tf.train.GradientDescentOptimizer(learning_rate = learning_rate)\n",
    "training_op = optimizer2.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            #print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "            pass\n",
    "        sess.run(training_op)     \n",
    "    best_theta = theta.eval()\n",
    "best_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Placeholder values are used to pass values to tensorflow ops\n",
    "A = tf.placeholder(tf.float32,shape = (None, 3))\n",
    "B = A + 5\n",
    "with tf.Session() as sess:\n",
    "    B_val_1 = B.eval(feed_dict = {A:[[1, 2, 3]]})\n",
    "    B_val_2 = B.eval(feed_dict = {A:[[4, 5, 6], [7, 8, 9]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "[[2.]]\n"
     ]
    }
   ],
   "source": [
    "A = tf.constant(F[:,0], shape = [nsamples,1], name = \"X\",dtype = tf.float64)\n",
    "B = tf.constant(F[:,1], shape = [nsamples,1], name = \"y\",dtype = tf.float64)\n",
    "batch_size, m, n_epochs, learning_rate = nsamples/5, nsamples, 5, 0.01\n",
    "n_batches = int(np.ceil(m/batch_size))\n",
    "X1 = tf.placeholder(tf.float64, shape = [batch_size,1], name = \"x\")\n",
    "y1 = tf.placeholder(tf.float64, shape = [batch_size,1], name = \"y\")\n",
    "theta = tf.Variable(tf.cast(tf.Variable(tf.random_uniform([1, 1], -1.0, 1.0), name = \"theta\"), tf.float64))\n",
    "y_pred = tf.matmul(X1, theta, name = \"predictions\")\n",
    "error = y_pred - y1\n",
    "mse = tf.reduce_mean(tf.square(error),name = \"mse\")\n",
    "gradients = tf.gradients(mse, [theta])[0]\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "def fetch_batch(batch_index, batch_size):\n",
    "    a_batch = tf.placeholder(tf.float64, shape = [batch_size,1], name = \"x\")\n",
    "    b_batch = tf.placeholder(tf.float64, shape = [batch_size,1], name = \"x\")\n",
    "    a_batch = A[batch_size * batch_index:batch_size * (batch_index + 1)].eval()\n",
    "    b_batch = B[batch_size * batch_index:batch_size * (batch_index + 1)].eval()\n",
    "    return a_batch, b_batch\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict = {X1:X_batch ,y1:y_batch})\n",
    "        print(epoch)\n",
    "    best_theta = theta.eval()\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and restoring models(in case of computer crash)\n",
    "#saver = tf.train.Saver()\n",
    "#save_path = saver.save(sess, \"/tmp/my_model.ckpt\")\n",
    "#with tf.Session() as sess:\n",
    "    #saver.restore(sess, \"/tmp/my_model_final.ckpt\")\n",
    "    #More code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sharing variables\n",
    "#def relu(X, threshold):\n",
    "    #with tf.name_scope(\"relu\"):\n",
    "        #[...]\n",
    "        #return tf.maximum(z, threshold, name = \"max\")\n",
    "\n",
    "#n_features = 2\n",
    "#threshold = tf.Variable(0.0, name = \"threshold\")\n",
    "#X = tf.placeholder(tf.float32, shape = (None, n_features), name = \"X\")\n",
    "#relus = [relu(X, threshold) for i in range(5)]\n",
    "#output = tf.add_n(relus,name = \"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with tf.variable_scope(\"relu\", reuse = True) as scope:\n",
    "    #scope.reuse_variables()\n",
    "    #threshold = tf.get_variable(\"threshold\", shape = (), initializer = tf.constant_initializer(0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def relu(X):\n",
    "    #with tf.variable_scope(\"relu\",reuse = True):\n",
    "        #threshold = tf.get_variable(\"threshold\") # reuse existing variable\n",
    "        #[...]\n",
    "        #return tf.maximum(z, threshold, name = \"max\")\n",
    "\n",
    "#X = tf.placeholder(tf.float32, shape = (None, n_features), name = \"X\")\n",
    "#with tf.variable_scope(\"relu\"):\n",
    "    # create the variable\n",
    "    #threshold = tf.get_variable(\"threshold\", shape = (), initializer = tf.constant_initializer(0.0))\n",
    "    #relus = [relu(X) for relu_index in range(5)]\n",
    "    #output = tf.add_n(relus, name = \"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
